#!/usr/bin/env python
import os, re, bs4, sys, requests, time, argparse, subprocess, urllib, json, urllib2, pyperclip
url='https://encrypted.google.com'
g='https://www.google.co.in/search?q='
yt='https://www.youtube.com/'
wiki='https://en.wikipedia.org/wiki/'
webdict = 'http://dictionary.reference.com/browse/'
gmap = 'http://maps.google.com/?q='
def list2str(var):
    return ' '.join(var)
def openweb(url):
    DEVNULL = open(os.devnull,'w')
    subprocess.call(['xdg-open',url],stdout=DEVNULL,stderr=subprocess.STDOUT)

def get_soup(args):
    return bs4.BeautifulSoup(requests.get(args).text,'html.parser')

#get dicitionary definition
#scraping from html src

def scrape_dict(args):
    soup = get_soup(webdict+args)
    print soup.select('.head-entry')[0].get_text().replace('\n','').title()
    link = soup.select('.def-content')
    for line in link:
        print line.get_text().rstrip()

#open website from google search result
'''
def json_dict(args):
    src='https://glosbe.com/gapi/translate?from=eng&dest=eng&format=json&phrase=%s&pretty=true'%(args)
    data=json.loads(urllib2.urlopen(src).read())
    print data
'''

def scrape_google(key):
    soup = get_soup(g + key.strip())
    if not soup:
        print 'Failed to load page'
        sys.exit(1)
    link = soup.select('.r a')
    openweb(g + link[0].get('href') )
    time.sleep(5)

#get wiki definition/first 10 lines from search result and display to terminal
def scrape_wiki(key):
    src=urllib.urlopen(wiki+key.strip())

    soup = get_soup(wiki+key.strip())
    data = soup.select('p')
    ctr = 0
    for line in data:
        txt = line.get_text().rstrip()
        rgx = re.compile(r'\[\d+\]')
        print rgx.sub('',txt)
        if ctr == 8:
            break
        ctr+=1

def delay_print(text):
    for  i in text:
        sys.stdout.write(i)
        sys.stdout.flush()
        time.sleep(.01599)

#main utility
def main(args):
    global g,yt,webdict,wiki,gmap,url
    if args.default:
        url = list2str(args.default)
        if url:
            if not re.match(r'\S+\.(co|in|xyz|org|com)\S*',url,re.IGNORECASE):
                url = g + url
            if not re.search(r'^http(s)?:\/\/',url):
                url='http://' + url
    elif args.googlemap:
        key = args.googlemap
        url = gmap + key
    elif args.google:
        key = list2str(args.google)
        url = g + key
    elif args.youtube:
        key = ' '.join(args.youtube)
        url= yt+"results?search_query=" + key
    elif args.wiki:
        key = args.wiki
        if args.open:
            openweb(wiki+key)
        else:
            scrape_wiki(key)
        return None
    elif args.dictionary:
        key = args.dictionary
        if args.open:
            openweb(webdict+key)
        else:
            scrape_dict(key)
        return None
    elif args.urbandict:
        key = list2str(args.urbandict)
        url = 'http://api.urbandictionary.com/v0/define?term='+key
        src = urllib.urlopen(url).read()
        src = json.loads(src)
        result = src["list"]
        ctr = 0
        print "Word:"+key.upper()
        for res in result:
            delay_print("["+str(ctr)+"]"+" "+res["definition"])
            print "\nExample:"
            delay_print( res["example"])
            print "\n"
            ctr += 1
            if ctr == 3:
                break
        return None
    elif args.weather:
        os.system('curl "http://wttr.in/%s"'%(args.weather))
        return None
    elif args.shortner:
        BITLY_TOKEN = os.getenv("BITLY_ACCESS_TOKEN")
        url = args.shortner
        if not re.search("http",url):
            url = "http://" + url
        url = "https://api-ssl.bitly.com/v3/shorten?access_token=%s&longUrl=%s&format=txt"%(BITLY_TOKEN,url)
        short_url = urllib.urlopen(url).read().strip("\n")
        pyperclip.copy(short_url)
        print "given short url copied to the clipboard"
        print short_url
        return None
    openweb(url)
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Terminal Utility to extract/open webpages')
    exgroup = parser.add_mutually_exclusive_group()
    parser.add_argument('default',nargs='*',help='directly open webpage if domain name is specified else will give google search result')
    exgroup.add_argument('-g','--google',nargs='+',help="open browser with google search result for given args")
    exgroup.add_argument('-yt','--youtube',nargs='+',help="open browser with youtube search result for given args")
    exgroup.add_argument('-wk','--wiki',type=str,help='extract wikipedia search/page result for given args and display on terminal')
    exgroup.add_argument('-dict','--dictionary',type=str,help='extract dictionary definition for given word and display on terminal')
    parser.add_argument('-o','--open',action='store_true',help='Open Webpage instead of displaying result on terminal; use with -wk/--wiki and -d/--dict')
    exgroup.add_argument('-map','--googlemap',type=str,help='open browser with Google-Map search result')
    exgroup.add_argument('-ud','--urbandict',nargs='+',help='definition from urbandictionary.com')
    exgroup.add_argument('-w','--weather',type=str,help='display weather info for given city')
    exgroup.add_argument('-s','--shortner',type=str, help="Shortene urls with bit.ly")
    args = parser.parse_args()
    main(args)
